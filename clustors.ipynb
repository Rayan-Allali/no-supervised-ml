{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d420b12a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.cluster import DBSCAN\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.io import arff\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "from yellowbrick.cluster import KElbowVisualizer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn_extra.cluster import KMedoids\n",
    "import os\n",
    "import scipy.cluster.hierarchy as sch\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from sklearn.metrics import silhouette_score\n",
    "from IPython.display import display\n",
    "from ipywidgets import widgets,interact, IntSlider"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c6d5d8ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def readArffFile(file):\n",
    "    data ,meta = arff.loadarff(file)\n",
    "    df = pd.DataFrame(data)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8c66133f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalization(data):\n",
    "    normalized_data = pd.DataFrame()\n",
    "    for col in data.columns:\n",
    "            normalized_data[col] = (data[col] - data[col].mean()) / data[col].std()\n",
    "    return normalized_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ce2354a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(df):\n",
    "    print(df.head(10))\n",
    "    dfBoxPlot = pd.DataFrame()\n",
    "    df=df.replace('?', np.nan)\n",
    "    for col in df.columns:\n",
    "        if df[col].dtype in ['float64', 'int64']:\n",
    "            dfBoxPlot[col] = df[col]\n",
    "            q1=df[col].quantile(0.25)\n",
    "            q3=df[col].quantile(0.75)\n",
    "            print(\"\\n\") \n",
    "            print(f\"column name : {col}\")\n",
    "            print(f\"column median : {df[col].median()}\")\n",
    "            print(f\"column mode : {df[col].mode()[0]}\")\n",
    "            print(f\"column first quartile: {q1}\")\n",
    "            print(f\"column third quartile: {q3}\")\n",
    "            print(f\"column unique values : {df[col].unique()}\") \n",
    "            print(\"\\n\")\n",
    "            QRI = 1.5*(q3 - q1)\n",
    "            if(df[col].any() > q3+QRI or df[col].any() < q1 - QRI):\n",
    "                  df[col] = (df[col] - df[col].mean()) / df[col].std()\n",
    "                  \n",
    "        else:\n",
    "            print(\"\\n\") \n",
    "            print(f\"column name : {col}\")\n",
    "            print(f\"column mode : {df[col].mode()[0]}\") \n",
    "            print(f\"column unique values : {df[col].unique()}\") \n",
    "            print(\"\\n\")\n",
    "    if df.any().any():\n",
    "        imputer = SimpleImputer(strategy='most_frequent')\n",
    "        updated_data = imputer.fit_transform(df)\n",
    "        df = pd.DataFrame(updated_data, columns=df.columns)\n",
    "    print(\"dfBoxPlot\")\n",
    "    print(dfBoxPlot)\n",
    "    if not dfBoxPlot.empty:\n",
    "        dfBoxPlot.boxplot()\n",
    "        plt.xticks(rotation=45)\n",
    "        plt.title('Boxplots of Attributes')\n",
    "        plt.xlabel('Attributes')\n",
    "        plt.ylabel('Values')\n",
    "        plt.show()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6911a7a",
   "metadata": {},
   "source": [
    "# one hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4002121b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoding_data(data):\n",
    "    numerical_cols = data.select_dtypes(include=['number']).columns\n",
    "    categorical_cols = data.select_dtypes(exclude=['number']).columns\n",
    "\n",
    "    encoded_categorical_cols = pd.get_dummies(data[categorical_cols])\n",
    "\n",
    "    preprocessed_data = pd.concat([data[numerical_cols], encoded_categorical_cols], axis=1)\n",
    "\n",
    "    return preprocessed_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6e98eb5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def readCsvFile(file):\n",
    "    data = pd.read_csv(file)\n",
    "    return data   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "36e792d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def listAllFilesInDirectory(dirPath):\n",
    "    files = os.listdir(dirPath)\n",
    "    return files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fe9cbde9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def readFile(fileName):\n",
    "    file_path = fr'C:\\Users\\DELL\\Downloads\\Data-20240416T120255Z-001\\Data\\{fileName}'\n",
    "    df={}\n",
    "    if(fileName.endswith(\"csv\")):\n",
    "        df=readCsvFile(file_path)\n",
    "    else:\n",
    "        df =readArffFile(file_path)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dde7e4a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_dataframe(df):\n",
    "    for col in df.columns:\n",
    "        if df[col].dtype == 'object':\n",
    "            df[col] = df[col].apply(lambda x: x.decode('utf-8') if isinstance(x, bytes) else x)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "232afbfc",
   "metadata": {},
   "source": [
    "# clustring"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "090f3c96",
   "metadata": {},
   "source": [
    "# k-mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2131f119",
   "metadata": {},
   "outputs": [],
   "source": [
    "def kmeans(data, n_clusters):\n",
    "    kmeans = KMeans(n_clusters=n_clusters)\n",
    "    kmeans.fit(data)\n",
    "    labels = kmeans.labels_\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee0cf71f",
   "metadata": {},
   "source": [
    "# kmedoids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ce4fc6e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def kmedoids(data, n_clusters):\n",
    "    kmedoids = KMedoids(n_clusters=n_clusters)\n",
    "    labels = kmedoids.fit_predict(data)\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06d253b5",
   "metadata": {},
   "source": [
    "# DbScan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c93b0234",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dbScan(data):\n",
    "    print(data)\n",
    "    dbscan = DBSCAN(eps=5, min_samples=4)\n",
    "    dbscan_model = dbscan.fit(data)\n",
    "    labels = dbscan_model.labels_\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "521774e2",
   "metadata": {},
   "source": [
    "# Agnes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "faa2e0c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Agnes(data, n_clusters):\n",
    "    dendrogram = sch.dendrogram(sch.linkage(data, method='ward'))\n",
    "    plt.title('Dendrogram')\n",
    "    plt.xlabel('Samples')\n",
    "    plt.ylabel('Distance')\n",
    "    plt.show()\n",
    "\n",
    "    hc = AgglomerativeClustering(n_clusters=n_clusters, affinity='euclidean', linkage='ward')\n",
    "    labels = hc.fit_predict(data)\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02db6c47",
   "metadata": {},
   "source": [
    "# Diana"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "643b76f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Diana(data, n_clusters):\n",
    "    dendrogram = sch.dendrogram(sch.linkage(data, method='ward'))\n",
    "    plt.title('Dendrogram')\n",
    "    plt.xlabel('Samples')\n",
    "    plt.ylabel('Distance')\n",
    "    plt.show()\n",
    "\n",
    "    hc = AgglomerativeClustering(n_clusters=1, affinity='euclidean', linkage='ward')\n",
    "    labels = hc.fit_predict(data)\n",
    "\n",
    "    for i in range(1, n_clusters):\n",
    "        hc = AgglomerativeClustering(n_clusters=i+1, affinity='euclidean', linkage='ward')\n",
    "        labels = hc.fit_predict(data)\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be047a95",
   "metadata": {},
   "source": [
    "# elbow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "70699f0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def elbow(data,model):\n",
    "    print(model)\n",
    "    k_range = range(1, 20)  \n",
    "    if model == \"KMeans\":\n",
    "        model = KMeans()\n",
    "    elif model == \"KMedoids\":\n",
    "        model = KMedoids()\n",
    "        \n",
    "    visualizer = KElbowVisualizer(model, k=k_range)\n",
    "\n",
    "\n",
    "    visualizer.fit(data)\n",
    "\n",
    "\n",
    "    visualizer.show()\n",
    "    return visualizer.elbow_value_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c346c15d",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'N_buttons' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_7148\\808114837.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     49\u001b[0m              \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"you have to choose file first to be able to pre process \"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 51\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mN_buttons\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     52\u001b[0m     \u001b[0mbuttons\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_click\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mchoseFile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'N_buttons' is not defined"
     ]
    }
   ],
   "source": [
    "files = os.listdir(r\"C:\\Users\\DELL\\Downloads\\Data-20240416T120255Z-001\\Data\")\n",
    "filesNp =np.array(files)\n",
    "buttons=[widgets.Button(description = file.split(\".\")[0]) for file in files]\n",
    "choosedFile = None\n",
    "isPrep_proced = False\n",
    "outputs=widgets.HBox([items for items in buttons])\n",
    "df = None\n",
    "\n",
    "def Clustoring(x):\n",
    "    global isPrep_proced\n",
    "    if(not isPrep_proced):\n",
    "        print(\"you cant make clustors without pre process data\")\n",
    "    else:\n",
    "        nClusterKmean = elbow(df,\"KMeans\")\n",
    "        nClusterKMedoids = elbow(df,\"KMedoids\")\n",
    "        kmeans_labels = kmeans(df,nClusterKmean)\n",
    "        kmedoids_labels = kmedoids(df,nClusterKMedoids)\n",
    "        Agnes_labels=Agnes(df,nClusterKmean)\n",
    "        Diana_labels=Diana(df,nClusterKMedoids)\n",
    "        dbScan_labels=dbScan(df)\n",
    "        kmedoids_silhouette_score =silhouette_score(daff, kmedoids_labels)\n",
    "        kmeans_silhouette_score =silhouette_score(daff, kmeans_labels)\n",
    "def choseFile(x):\n",
    "    global choosedFile \n",
    "    global df\n",
    "    index = np.where([file.split(\".\")[0] == x.description for file in files])[0][0]\n",
    "    choosedFile = filesNp[index]\n",
    "    df=readFile(choosedFile)\n",
    "    print(choosedFile)\n",
    "    if(filesNp[index].split(\".\")[1] == \"arff\"):\n",
    "        df = update_dataframe(df)\n",
    "    print(df)\n",
    "def preProcessing(x):\n",
    "        global choosedFile \n",
    "        global isPrep_proced\n",
    "        global df\n",
    "        if choosedFile is not None:\n",
    "                if \"Class\" in daff.columns :\n",
    "                    df.drop('Class', axis=1, inplace=True)\n",
    "                if \"class\" in daff.columns :\n",
    "                    df.drop('class', axis=1, inplace=True)\n",
    "                non_numeric_columns = df.select_dtypes(exclude=['number']).columns\n",
    "                if len(non_numeric_columns) > 0:\n",
    "                    print(\"no num\")\n",
    "                    df = encoding_data(df)\n",
    "                df=preprocessing(df)\n",
    "                isPrep_proced=True\n",
    "        else:\n",
    "             print(\"you have to choose file first to be able to pre process \")\n",
    "\n",
    "for i in range(N_buttons):\n",
    "    buttons[i].on_click(choseFile)\n",
    "    \n",
    "buttonShowDatasets = widgets.Button(description='Show Data')\n",
    "buttonpreProcessing = widgets.Button(description='preProcessing')\n",
    "buttonClustoring = widgets.Button(description='Clustoring')\n",
    "def showDataSets(b):\n",
    "    if outputs.layout.display == 'none':\n",
    "        outputs.layout.display = 'flex'\n",
    "        b.description = 'Hide Data'\n",
    "    else:\n",
    "        outputs.layout.display = 'none'\n",
    "        b.description = 'Show Data'\n",
    "\n",
    "buttonShowDatasets.on_click(showDataSets)\n",
    "buttonpreProcessing.on_click(preProcessing)\n",
    "buttonClustoring.on_click(Clustoring)\n",
    "display(buttonShowDatasets)\n",
    "\n",
    "outputs.layout.display = 'none'\n",
    "\n",
    "display(outputs)\n",
    "display(buttonpreProcessing)\n",
    "display(buttonClustoring)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
