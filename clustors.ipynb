{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d420b12a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.cluster import DBSCAN\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.io import arff\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "from yellowbrick.cluster import KElbowVisualizer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn_extra.cluster import KMedoids\n",
    "import os\n",
    "import scipy.cluster.hierarchy as sch\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from sklearn.metrics import silhouette_score\n",
    "from IPython.display import display\n",
    "from ipywidgets import widgets,interact, IntSlider,Output, VBox,HTML\n",
    "from kneed import KneeLocator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c72023e",
   "metadata": {},
   "source": [
    "# manipulating files\n",
    "Ces fonctions sont utilisées pour manipuler différents fichiers (arff/csv) and listing files in répertoires"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c6d5d8ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def readArffFile(file):\n",
    "    data ,meta = arff.loadarff(file)\n",
    "    df = pd.DataFrame(data)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6e98eb5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def readCsvFile(file):\n",
    "    data = pd.read_csv(file)\n",
    "    return data   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fe9cbde9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def readFile(fileName):\n",
    "    file_path = fr'C:\\Users\\DELL\\Downloads\\Data-20240416T120255Z-001\\Data\\{fileName}'\n",
    "    df={}\n",
    "    if(fileName.endswith(\"csv\")):\n",
    "        df=readCsvFile(file_path)\n",
    "    else:\n",
    "        df =readArffFile(file_path)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "36e792d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def listAllFilesInDirectory(dirPath):\n",
    "    files = os.listdir(dirPath)\n",
    "    return files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9c7328e",
   "metadata": {},
   "source": [
    "Cette fonction va transformer les données de type binaire en UTF-8 (données normales)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dde7e4a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_dataframe(df):\n",
    "    for col in df.columns:\n",
    "        if df[col].dtype == 'object':\n",
    "            df[col] = df[col].apply(lambda x: x.decode('utf-8') if isinstance(x, bytes) else x)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b83c4bd5",
   "metadata": {},
   "source": [
    "# preprocessing \n",
    "Le preprocessing est une étape essentielle Dans cette étape, nous nettoyons les données ,en montrant une description de notre data, en remplaçant les valeurs manquantes et en normalisant les données si nécessaire. Tout cela est crucial avant toute opération de regroupement ou d'analyse de données.\n",
    "\n",
    "### Paramètres :\n",
    "- `df` : notre data frame\n",
    "### Retours :\n",
    "- `df` : notre dataframe apres preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ce2354a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(df):\n",
    "    global preprocess_output\n",
    "    with preprocess_output:\n",
    "        preprocess_output.clear_output()\n",
    "        display_df(df.head(10))\n",
    "    dfBoxPlot = pd.DataFrame()\n",
    "    df=df.replace('?', np.nan)\n",
    "    for col in df.columns:\n",
    "        if df[col].dtype in ['float64', 'int64']:\n",
    "            dfBoxPlot[col] = df[col]\n",
    "            q1=df[col].quantile(0.25)\n",
    "            q3=df[col].quantile(0.75)\n",
    "            with preprocess_output:\n",
    "                display(HTML(\"\"))\n",
    "                display(HTML(f\"column name : {col}\"))\n",
    "                display(HTML(f\"column median : {df[col].median()}\"))\n",
    "                display(HTML(f\"column mode : {df[col].mode()[0]}\"))\n",
    "                display(HTML(f\"column unique values : {df[col].unique()}\"))\n",
    "                display(HTML(\"\"))\n",
    "            QRI = 1.5*(q3 - q1)\n",
    "            if(df[col].any() > q3+QRI or df[col].any() < q1 - QRI):\n",
    "                  df[col] = (df[col] - df[col].mean()) / df[col].std()\n",
    "                  \n",
    "        else:\n",
    "            with preprocess_output:\n",
    "                display(HTML(\"\"))\n",
    "                display(HTML(f\"column name : {col}\"))\n",
    "                display(HTML(f\"column mode : {df[col].mode()[0]}\"))\n",
    "                display(HTML(f\"column unique values : {df[col].unique()}\"))\n",
    "                display(HTML(\"\"))\n",
    "    if df.isna().any().any():\n",
    "        imputer = SimpleImputer(strategy='most_frequent')\n",
    "        updated_data = imputer.fit_transform(df)\n",
    "        df = pd.DataFrame(updated_data, columns=df.columns)\n",
    "    with preprocess_output:\n",
    "        displayboxplot(dfBoxPlot)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6911a7a",
   "metadata": {},
   "source": [
    "# one hot encoding\n",
    "Cette fonction nous aidera à travailler avec des données catégorielles en utilisant sklearn. Les fonctions de sklearn ne prennent pas en charge les données catégorielle\n",
    "\n",
    "### Paramètres :\n",
    "- `data` : notre dataframe\n",
    "\n",
    "### Retours :\n",
    "- `data` : notre dataframe apres codage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4002121b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoding_data(data):\n",
    "    numerical_cols = data.select_dtypes(include=['number']).columns\n",
    "    categorical_cols = data.select_dtypes(exclude=['number']).columns\n",
    "\n",
    "    encoded_categorical_cols = pd.get_dummies(data[categorical_cols])\n",
    "\n",
    "    preprocessed_data = pd.concat([data[numerical_cols], encoded_categorical_cols], axis=1)\n",
    "\n",
    "    return preprocessed_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "232afbfc",
   "metadata": {},
   "source": [
    "# clustring"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "090f3c96",
   "metadata": {},
   "source": [
    "# k-mean\n",
    "Cette fonction est utilisee pour effectuer un regroupement k-mean\n",
    "\n",
    "### Paramètres :\n",
    "- `data` : Les donnees d'entre pour le regroupement.\n",
    "- `n_clusters` : Le nombre de clusters selon l'elbow.\n",
    "\n",
    "### Retours :\n",
    "- `k-mean` : Le modele k-mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2131f119",
   "metadata": {},
   "outputs": [],
   "source": [
    "def kmeans(data, n_clusters):\n",
    "    kmeans = KMeans(n_clusters=n_clusters)\n",
    "    kmeans.fit(data)\n",
    "    return kmeans"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee0cf71f",
   "metadata": {},
   "source": [
    "# kmedoids\n",
    "Cette fonction est utilisée pour effectuer un clustoring kmedoids \n",
    "\n",
    "### Paramètres :\n",
    "- `data` : Les données d'entrée pour le regroupement.\n",
    "- `n_clusters` : Le nombre de clusters selon l'elbow.\n",
    "\n",
    "### Retours :\n",
    "- `kmedoids` : Le modele kmedoids.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ce4fc6e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def kmedoids(data, n_clusters):\n",
    "    kmedoids = KMedoids(n_clusters=n_clusters)\n",
    "    kmedoids.fit_predict(data)\n",
    "    return kmedoids"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17206a21",
   "metadata": {},
   "source": [
    "# DbScan\n",
    "Cette fonction est utilisee pour effectuer un regroupement DBSCAN \n",
    "### Paramètres :\n",
    "- `data` : Les donnees d'entree pour le regroupement.\n",
    "- `eps_range` : Un tuple specifiant la plage de valeurs epsilon a considerer pour DBSCAN. Par défaut, c'est (0.05, 40.1).\n",
    "- `min_pts_range` : Un tuple specifiant la plage de points minimums pour DBSCAN. Par defaut, c'est (4, 20).\n",
    "\n",
    "### Retours :\n",
    "- `best_model` : Le modele DBSCAN avec le score de silhouette le plus eleve.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dc4169a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dbScan(data, eps_range=(0.05, 40.1), min_pts_range=(4, 20)):\n",
    "\n",
    "    best_model = None\n",
    "    best_score = -1\n",
    "\n",
    "    for eps in eps_range:\n",
    "        for min_pts in min_pts_range:\n",
    "            model = DBSCAN(eps=eps, min_samples=min_pts)\n",
    "            model.fit(data)\n",
    "            if(model is not None):\n",
    "                labels = model.labels_\n",
    "                if  np.all(labels == -1):\n",
    "                    print(\"All data points are considered noise. Skipping DBSCAN.\")\n",
    "                    continue \n",
    "                if  np.all(labels == 0):\n",
    "                    print(\"All data points are considered noise. Skipping DBSCAN.\")\n",
    "                    continue \n",
    "                score = silhouette_score(data, labels)\n",
    "                print(score)\n",
    "                if score > best_score:\n",
    "                    best_model = model\n",
    "                    best_score = score\n",
    "\n",
    "    return best_model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "521774e2",
   "metadata": {},
   "source": [
    "# Agnes\n",
    "Cette fonction est utilisee pour effectuer un regroupement Agnes \n",
    "### Paramètres :\n",
    "- `data` : Les donnees d'entree pour le regroupement.\n",
    "- `n_clusters` : nombre de clusters\n",
    "\n",
    "### Retours :\n",
    "- `Agnes model` : Le modele Agnes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "faa2e0c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Agnes(data, n_clusters):\n",
    "    with clustoring_output:\n",
    "        dendrogram = sch.dendrogram(sch.linkage(data, method='ward'))\n",
    "        plt.title('Dendrogram Agnes')\n",
    "        plt.xlabel('Samples')\n",
    "        plt.ylabel('Distance')\n",
    "        plt.show()\n",
    "\n",
    "    hc = AgglomerativeClustering(n_clusters=n_clusters, affinity='euclidean', linkage='ward')\n",
    "    labels = hc.fit_predict(data)\n",
    "    return hc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02db6c47",
   "metadata": {},
   "source": [
    "# Diana\n",
    "Cette fonction est utilisee pour effectuer un regroupement Diana \n",
    "### Paramètres :\n",
    "- `data` : Les donnees d'entree pour le regroupement.\n",
    "- `n_clusters` : nombre de clusters\n",
    "\n",
    "### Retours :\n",
    "- `Diana model` : Le modele Diana"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "643b76f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Diana(data, n_clusters):\n",
    "    with clustoring_output:\n",
    "        dendrogram = sch.dendrogram(sch.linkage(data, method='ward'))\n",
    "        plt.title('Dendrogram Diana')\n",
    "        plt.xlabel('Samples')\n",
    "        plt.ylabel('Distance')\n",
    "        plt.show()\n",
    "\n",
    "    hc = AgglomerativeClustering(n_clusters=1, affinity='euclidean', linkage='ward')\n",
    "    labels = hc.fit_predict(data)\n",
    "\n",
    "    for i in range(1, n_clusters):\n",
    "        hc = AgglomerativeClustering(n_clusters=i+1, affinity='euclidean', linkage='ward')\n",
    "        labels = hc.fit_predict(data)\n",
    "    return hc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be047a95",
   "metadata": {},
   "source": [
    "# elbow\n",
    "### Paramètres :\n",
    "- `data` : Les données d'entrée pour le regroupement.\n",
    "- `model` : kmean or kmedoids \n",
    "\n",
    "### Retours :\n",
    "- `elbow_value`:best nbr of cluster "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "70699f0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def elbow(data,model):\n",
    "    k_range = range(1, 20)  \n",
    "    if model == \"KMeans\":\n",
    "        model = KMeans()\n",
    "    elif model == \"KMedoids\":\n",
    "        model = KMedoids()\n",
    "        \n",
    "    with clustoring_output:\n",
    "        visualizer = KElbowVisualizer(model, k=k_range)\n",
    "\n",
    "\n",
    "        visualizer.fit(data)\n",
    "\n",
    "\n",
    "        visualizer.show()\n",
    "    return visualizer.elbow_value_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "64c4946e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "edb3a2b0f8bc4e768fb9307ebe8f92af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Show Data', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8805219ac7d840cfb2ea16b5034b44dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Button(description='breast', style=ButtonStyle()), Button(description='contact-lenses', style=B…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e249c9e6421a44b69064fa686fca37fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Output(layout=Layout(width='100%')),))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49684bca542e4cefae80c017825f33f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='preProcessing', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f07ab59d9d8341f3a07028515dbfc31f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Output(layout=Layout(width='100%')),))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "706d45c95b5042178de6819503628e7d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Clustoring', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ef42dce183246548945e544d939beef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Output(layout=Layout(width='100%')),))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "files = os.listdir(r\"C:\\Users\\DELL\\Downloads\\Data-20240416T120255Z-001\\Data\")\n",
    "filesNp =np.array(files)\n",
    "buttons=[widgets.Button(description = file.split(\".\")[0]) for file in files]\n",
    "choosedFile = None\n",
    "isPrep_proced = False\n",
    "outputs=widgets.HBox([items for items in buttons])\n",
    "df = None\n",
    "df_output = Output(layout={'width': '100%'})\n",
    "preprocess_output= Output(layout={'width': '100%'})\n",
    "clustoring_output = Output(layout={'width': '100%'})\n",
    "\n",
    "def display_df(df):\n",
    "    html_table = df.to_html()\n",
    "    styled_html = f\"\"\"\n",
    "    <style>\n",
    "        table {{ width: 150%; }}  </style>\n",
    "    {html_table}\n",
    "    \"\"\"\n",
    "    display(HTML(styled_html))\n",
    "        \n",
    "def displayboxplot(dfBoxPlot):\n",
    "        with preprocess_output:\n",
    "            if not dfBoxPlot.empty:\n",
    "                dfBoxPlot.boxplot()\n",
    "                plt.xticks(rotation=45)\n",
    "                plt.title('Boxplots of Attributes')\n",
    "                plt.xlabel('Attributes')\n",
    "                plt.ylabel('Values')\n",
    "                plt.show()      \n",
    "        \n",
    "def Clustoring(x):\n",
    "    global isPrep_proced\n",
    "    if(not isPrep_proced):\n",
    "        error_message = \"you cant make clustors without pre process data.\"\n",
    "        with clustoring_output:\n",
    "                clustoring_output.clear_output() \n",
    "                display(HTML(error_message))\n",
    "    else:\n",
    "        with clustoring_output:\n",
    "            clustoring_output.clear_output() \n",
    "        nClusterKmean = elbow(df,\"KMeans\")\n",
    "        nClusterKMedoids = elbow(df,\"KMedoids\")\n",
    "        kmeans_model = kmeans(df,nClusterKmean)\n",
    "        kmeans_labels = kmeans_model.labels_\n",
    "        labels_df = pd.DataFrame({'label': kmeans_labels}) \n",
    "        with clustoring_output:\n",
    "            predicted_labels = kmeans_model.predict(df)\n",
    "            dfKmean =df.copy()\n",
    "            dfKmean['cluster'] = predicted_labels\n",
    "            title_kmean = \"\"\"<h1 style=\"font-size: 4em; margin: 1em 0; text-align: center;\">KMeans Clustering</h1>\"\"\"\n",
    "            display(HTML(title_kmean))\n",
    "            display_df(dfKmean)\n",
    "        kmedoids_model = kmedoids(df,nClusterKMedoids)\n",
    "        kmedoids_labels = kmedoids_model.labels_\n",
    "        with clustoring_output:\n",
    "            predicted_labels = kmedoids_model.predict(df)\n",
    "            dfkmedoids =df.copy()\n",
    "            dfkmedoids['cluster'] = predicted_labels\n",
    "            title_kmedoids = \"\"\"<h1 style=\"font-size: 4em; margin: 1em 0; text-align: center;\">kmedoids Clustering</h1>\"\"\"\n",
    "            display(HTML(title_kmedoids))\n",
    "            display_df(dfkmedoids)\n",
    "        Agnes_model =Agnes(df,nClusterKmean)\n",
    "        Agnes_labels = Agnes_model.labels_\n",
    "        with clustoring_output:\n",
    "            predicted_labels = Agnes_model.fit_predict(df)\n",
    "            dfAgnes =df.copy()\n",
    "            dfAgnes['cluster'] = predicted_labels\n",
    "            title_agnes = \"\"\"<h1 style=\"font-size: 4em; margin: 1em 0; text-align: center;\">Agnes Clustering</h1>\"\"\"\n",
    "            display(HTML(title_agnes))\n",
    "            display_df(dfAgnes)\n",
    "        Diana_model=Diana(df,nClusterKMedoids)\n",
    "        Diana_labels = Diana_model.labels_\n",
    "        with clustoring_output:\n",
    "            predicted_labels = Diana_model.fit_predict(df)\n",
    "            dfDiana =df.copy()\n",
    "            dfDiana['cluster'] = predicted_labels\n",
    "            title_Diana = \"\"\"<h1 style=\"font-size: 4em; margin: 1em 0; text-align: center;\">Diana Clustering</h1>\"\"\"\n",
    "            display(HTML(title_Diana))\n",
    "            display_df(dfDiana)\n",
    "        \n",
    "        dbScan_model=dbScan(df)\n",
    "        if(dbScan_model is not None) : \n",
    "            dbScan_label = dbScan_model.labels_\n",
    "            with clustoring_output:\n",
    "                predicted_labels = dbScan_model.fit_predict(df)\n",
    "                dfdbScan =df.copy()\n",
    "                dbScan_model['cluster'] = predicted_labels\n",
    "                title_dbscan = \"\"\"<h1 style=\"font-size: 4em; margin: 1em 0; text-align: center;\">db scan Clustering</h1>\"\"\"\n",
    "                display(HTML(title_dbscan))\n",
    "                display_df(dbScan_model)\n",
    "            print (dbScan_label)\n",
    "            dbScan_silhouette_score= silhouette_score(df, dbScan_label)\n",
    "        kmedoids_silhouette_score =silhouette_score(df, kmedoids_labels)\n",
    "        kmeans_silhouette_score =silhouette_score(df, kmeans_labels)\n",
    "        Diana_silhouette_score =silhouette_score(df, Diana_labels)\n",
    "        Agnes_silhouette_score =silhouette_score(df, Agnes_labels)\n",
    "\n",
    "        with clustoring_output:\n",
    "            display(HTML(f\"kmedoids_silhouette_score:{kmedoids_silhouette_score}\"))\n",
    "            display(HTML(f\"kmeans_silhouette_score:{kmeans_silhouette_score}\"))\n",
    "            display(HTML(f\"Agnes_silhouette_score:{ Agnes_silhouette_score}\"))\n",
    "            display(HTML(f\"Diana_silhouette_score:{Diana_silhouette_score}\"))\n",
    "            if(dbScan_model is not None) : \n",
    "                display(HTML(f\"dbScan_silhouette_score:{dbScan_silhouette_score}\"))\n",
    "        if(dbScan_model is not None) : \n",
    "            method_scores = {\n",
    "                    \"KMeans\": kmeans_silhouette_score,  \n",
    "                    \"DBSCAN\": dbScan_silhouette_score, \n",
    "                    \"KMedoids\":kmedoids_silhouette_score,\n",
    "                    \"Agnes\":Agnes_silhouette_score,\n",
    "                    \"Diana\":Diana_silhouette_score\n",
    "                }\n",
    "        else :\n",
    "            method_scores = {\n",
    "                    \"KMeans\": kmeans_silhouette_score,\n",
    "                    \"KMedoids\":kmedoids_silhouette_score,\n",
    "                    \"Agnes\":Agnes_silhouette_score,\n",
    "                    \"Diana\":Diana_silhouette_score\n",
    "                }\n",
    "        with clustoring_output:\n",
    "            plt.figure(figsize=(10, 6))\n",
    "            plt.bar(method_scores.keys(), method_scores.values())\n",
    "            plt.xlabel(\"Clustering Method\")\n",
    "            plt.ylabel(\"Silhouette Score\")\n",
    "            plt.title(\"Silhouette Score Comparison Across Clustering Methods\")\n",
    "            plt.grid(True)\n",
    "            plt.xticks(rotation=45, ha='right')  \n",
    "            plt.tight_layout()\n",
    "\n",
    "def choseFile(x):\n",
    "    global choosedFile \n",
    "    global df\n",
    "    index = np.where([file.split(\".\")[0] == x.description for file in files])[0][0]\n",
    "    choosedFile = filesNp[index]\n",
    "    df=readFile(choosedFile)\n",
    "    if(filesNp[index].split(\".\")[1] == \"arff\"):\n",
    "        df = update_dataframe(df)\n",
    "    with df_output:\n",
    "        df_output.clear_output()\n",
    "        display_df(df) \n",
    "def preProcessing(x):\n",
    "        global choosedFile \n",
    "        global isPrep_proced\n",
    "        global df\n",
    "        global preprocess_output\n",
    "        if choosedFile is not None:\n",
    "                if \"Class\" in df.columns :\n",
    "                    df.drop('Class', axis=1, inplace=True)\n",
    "                if \"class\" in df.columns :\n",
    "                    df.drop('class', axis=1, inplace=True)\n",
    "                non_numeric_columns = df.select_dtypes(exclude=['number']).columns\n",
    "                df=preprocessing(df)\n",
    "                if len(non_numeric_columns) > 0:\n",
    "                    df = encoding_data(df)\n",
    "                isPrep_proced=True\n",
    "        else:\n",
    "            error_message = \"You have to choose a file first to be able to pre-process.\"\n",
    "            with preprocess_output:\n",
    "                preprocess_output.clear_output() \n",
    "                display(HTML(error_message))\n",
    "\n",
    "for button in buttons:\n",
    "    button.on_click(choseFile)\n",
    "    \n",
    "buttonShowDatasets = widgets.Button(description='Show Data')\n",
    "buttonpreProcessing = widgets.Button(description='preProcessing')\n",
    "buttonClustoring = widgets.Button(description='Clustoring')\n",
    "def showDataSets(b):\n",
    "    if outputs.layout.display == 'none':\n",
    "        outputs.layout.display = 'flex'\n",
    "        b.description = 'Hide Data'\n",
    "    else:\n",
    "        outputs.layout.display = 'none'\n",
    "        b.description = 'Show Data'\n",
    "\n",
    "buttonShowDatasets.on_click(showDataSets)\n",
    "buttonpreProcessing.on_click(preProcessing)\n",
    "buttonClustoring.on_click(Clustoring)\n",
    "display(buttonShowDatasets)\n",
    "\n",
    "outputs.layout.display = 'none'\n",
    "df_vbox = VBox(children=[df_output])\n",
    "preproccess_vbox = VBox(children=[preprocess_output])\n",
    "clustorings_vbox = VBox(children=[clustoring_output])\n",
    "display(outputs)\n",
    "display(df_vbox)\n",
    "display(buttonpreProcessing)\n",
    "display(preproccess_vbox)\n",
    "display(buttonClustoring)\n",
    "display(clustorings_vbox)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c63f807c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2152a9e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c86d90ba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
